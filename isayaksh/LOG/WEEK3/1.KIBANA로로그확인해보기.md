# Kibana
- Docker 컨테이너로 실행되는 독립적인 애플리케이션
- Kibana를 사용하기 위해 Elasticsearch 필요
- Kibana가 Elasticsearch의 데이터를 조회하는 식으로 활용

# Kibana 실행 커맨드
```
docker run -d --name kibana --network elastic-network -p 5601:5601 -e "ELASTICSEARCH_HOSTS=http://elasticsearch:9200" kibana:8.10.1
```
- `-d`: 백그라운드 모드로 실행
- `--name kibana`: 컨테이너 이름을 'kibana'로 지정
- `--network elastic-network`: 도커 네트워크 'elastic-search'에 연결. 다른 컨테이너와 통신 가능
- `-p 5601:5601`: 호스트의 5601 포트를 컨테이너의 5601 포트에 매핑
- `-e "ELASTICSEARCH_HOSTS=..."`: Kibana가 연결할 Elasticsearch의 주소를 환경 변수로 설정

# Kibana 세팅
1. `localhost:5601` 접속
2. 좌측 상단의 메뉴바에서 `Discover` 클릭
3. `Create data view` 클릭
4. `data view` 생성
  - Name : data view의 이름(원하는대로)
  - Index pattern : `index-*`일 경우, `index-`로 시작하는 모든 데이터를 대상으로 검색하겠다는 의미
                    `Your index pattern can match 1 source.` 에서 내가 생성한 인덱스를 볼 수 있다.
                    만약 내가 생성한 인덱스(로그)가 `application-logs-2025-06-17`일 경우 index pattern을 `application-logs-*`로 만들면 된다.
  - Timestamp field : `@timestamp`가 default이다.
                      kibana는 시간순으로 데이터를 보여주는게 default이다.
5. `Savee data view to Kibana` 버튼 클릭


# 시간 차이 발생?
- 파일에 적용된 time pattern(`2025-06-17`)은 Logstash에서 지정된 시간이다. Docker 내에 실행중인 애플리케이션은 별도로 설정해주지 않으면 `UTC0`(한국시간 - 9시간)를 default 값으로 사용한다.
- `@timestamp`의 경우 애플리케이션 자체적으로 기록한다. 기준은 현재 PC의 시간이다.

# 로그 검색하기
- 로그 레벨에 맞추어 검색하기 위해서는 `level: "INFO"` 를 검색 키워드로 사용한다.
- 특정 필드의 존재하는 값을 검색하기 위해서는 `filed: "keyword"` 를 검색 키워드로 사용한다.
- 만약 여러개의 조건을 검색 조건으로 사용하기 위해서는 `AND` 키워드를 사용한다.